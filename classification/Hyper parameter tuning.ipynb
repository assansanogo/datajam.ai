{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<center><h1>DATAJAM.AI CATS & DOGS - <a style=\"color:red\">HYPERPARAMETERS TUNING</a> -</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/zJyLQ0s/Screen-Shot-2019-07-20-at-22-42-19.png\" style=\"width:300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner\n",
    "import  tensorflow as tf\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.applications import VGG16\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.compat.v1.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we limit the experiment to a few data points\n",
    "limits = 1000\n",
    "(x_train, y_train), (x_test, y_test) = (x_train[:limits], y_train[:limits]), (x_test[:limits], y_test[:limits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives us information on the number of classes predicted\n",
    "categories =  np.unique(y_train).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of data used for training \n",
    "ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_picture(x,y):\n",
    "    an_im = plt.imshow(x, cmap='gray')\n",
    "    plt.title(y)\n",
    "    plt.show()\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_me(x,size=(224,224),mode=cv2.INTER_CUBIC):\n",
    "    # resize the image to the network input shape\n",
    "    res= cv2.resize(x,(224,224),mode)\n",
    "    return(cv2.merge([res,res,res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 6843.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# we loop through all the images\n",
    "# resize the image with the function defined above\n",
    "# save the numpy array \"of the list\"\n",
    "\n",
    "l=[]\n",
    "for el in tqdm(x_train):\n",
    "    l.append(resize_me(el,size=(224,224),mode=cv2.INTER_CUBIC))\n",
    "x_train_new = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels= x_train_new[:int(ratio*x_train.shape[0])],y_train[:int(ratio*x_train.shape[0])]\n",
    "val_data, val_labels= x_train_new[int(ratio*x_train.shape[0]):],y_train[int(ratio*x_train.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), input_shape=(224, 224,3)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10))\n",
    "    model.add(layers.Dense(units=hp.Range('units',\n",
    "                                          min_value=32,\n",
    "                                          max_value=512,\n",
    "                                          step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing a structure (after downloading from VGG16)\n",
    "# grandomsearch : \n",
    "# on the number of dense layers\n",
    "# on the dropout values\n",
    "# on the learning reate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    categories=10\n",
    "    size=(224,224,3)\n",
    "\n",
    "    baseModel = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=size))\n",
    "\n",
    "    # construct the head of the model that will be placed on top of the\n",
    "    # the base model\n",
    "    headModel = baseModel.output\n",
    "    headModel = layers.Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = layers.Dense(units=hp.Range('units',\n",
    "                                     min_value=32,\n",
    "                                     max_value=512,\n",
    "                                     step=32), \n",
    "                      activation=\"relu\")(headModel)\n",
    "\n",
    "    headModel = layers.Dropout(hp.Choice('dropout', \n",
    "                                values=[0.1,0.2,0.3,0.4,0.5]))(headModel)\n",
    "    headModel = layers.Dense(categories, activation=\"softmax\")(headModel)\n",
    "\n",
    "    # place the head FC model on top of the base model (this will become\n",
    "    # the actual model we will train)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    model.compile(\n",
    "    optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate',\n",
    "                  values=[1e-2, 1e-3, 1e-4])),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">New model</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dropout: 0.3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Execution 1/3</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c17869239484df59d5c56e9e60e61f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search(train_data, train_labels,\n",
    "             epochs=5,\n",
    "             validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
